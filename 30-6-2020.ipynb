{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem that we are going to solve here is that given a set of features that describe a tumour whether it is Malignant or Benign, our machine learning model must predict whether the tumour is Malignant or Benign. To train our machine learning model with tumour data, we will be using Small Cell Lung Cancer dataset SCLCData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>87139402</td>\n",
       "      <td>B</td>\n",
       "      <td>12.32</td>\n",
       "      <td>12.39</td>\n",
       "      <td>78.85</td>\n",
       "      <td>464.1</td>\n",
       "      <td>0.10280</td>\n",
       "      <td>0.06981</td>\n",
       "      <td>0.03987</td>\n",
       "      <td>0.03700</td>\n",
       "      <td>...</td>\n",
       "      <td>13.50</td>\n",
       "      <td>15.64</td>\n",
       "      <td>86.97</td>\n",
       "      <td>549.1</td>\n",
       "      <td>0.1385</td>\n",
       "      <td>0.1266</td>\n",
       "      <td>0.12420</td>\n",
       "      <td>0.09391</td>\n",
       "      <td>0.2827</td>\n",
       "      <td>0.06771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>8910251</td>\n",
       "      <td>B</td>\n",
       "      <td>10.60</td>\n",
       "      <td>18.95</td>\n",
       "      <td>69.28</td>\n",
       "      <td>346.4</td>\n",
       "      <td>0.09688</td>\n",
       "      <td>0.11470</td>\n",
       "      <td>0.06387</td>\n",
       "      <td>0.02642</td>\n",
       "      <td>...</td>\n",
       "      <td>11.88</td>\n",
       "      <td>22.94</td>\n",
       "      <td>78.28</td>\n",
       "      <td>424.8</td>\n",
       "      <td>0.1213</td>\n",
       "      <td>0.2515</td>\n",
       "      <td>0.19160</td>\n",
       "      <td>0.07926</td>\n",
       "      <td>0.2940</td>\n",
       "      <td>0.07587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>905520</td>\n",
       "      <td>B</td>\n",
       "      <td>11.04</td>\n",
       "      <td>16.83</td>\n",
       "      <td>70.92</td>\n",
       "      <td>373.2</td>\n",
       "      <td>0.10770</td>\n",
       "      <td>0.07804</td>\n",
       "      <td>0.03046</td>\n",
       "      <td>0.02480</td>\n",
       "      <td>...</td>\n",
       "      <td>12.41</td>\n",
       "      <td>26.44</td>\n",
       "      <td>79.93</td>\n",
       "      <td>471.4</td>\n",
       "      <td>0.1369</td>\n",
       "      <td>0.1482</td>\n",
       "      <td>0.10670</td>\n",
       "      <td>0.07431</td>\n",
       "      <td>0.2998</td>\n",
       "      <td>0.07881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>868871</td>\n",
       "      <td>B</td>\n",
       "      <td>11.28</td>\n",
       "      <td>13.39</td>\n",
       "      <td>73.00</td>\n",
       "      <td>384.8</td>\n",
       "      <td>0.11640</td>\n",
       "      <td>0.11360</td>\n",
       "      <td>0.04635</td>\n",
       "      <td>0.04796</td>\n",
       "      <td>...</td>\n",
       "      <td>11.92</td>\n",
       "      <td>15.77</td>\n",
       "      <td>76.53</td>\n",
       "      <td>434.0</td>\n",
       "      <td>0.1367</td>\n",
       "      <td>0.1822</td>\n",
       "      <td>0.08669</td>\n",
       "      <td>0.08611</td>\n",
       "      <td>0.2102</td>\n",
       "      <td>0.06784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>9012568</td>\n",
       "      <td>B</td>\n",
       "      <td>15.19</td>\n",
       "      <td>13.21</td>\n",
       "      <td>97.65</td>\n",
       "      <td>711.8</td>\n",
       "      <td>0.07963</td>\n",
       "      <td>0.06934</td>\n",
       "      <td>0.03393</td>\n",
       "      <td>0.02657</td>\n",
       "      <td>...</td>\n",
       "      <td>16.20</td>\n",
       "      <td>15.73</td>\n",
       "      <td>104.50</td>\n",
       "      <td>819.1</td>\n",
       "      <td>0.1126</td>\n",
       "      <td>0.1737</td>\n",
       "      <td>0.13620</td>\n",
       "      <td>0.08178</td>\n",
       "      <td>0.2487</td>\n",
       "      <td>0.06766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0  87139402         B        12.32         12.39           78.85      464.1   \n",
       "1   8910251         B        10.60         18.95           69.28      346.4   \n",
       "2    905520         B        11.04         16.83           70.92      373.2   \n",
       "3    868871         B        11.28         13.39           73.00      384.8   \n",
       "4   9012568         B        15.19         13.21           97.65      711.8   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  points_mean  ...  \\\n",
       "0          0.10280           0.06981         0.03987      0.03700  ...   \n",
       "1          0.09688           0.11470         0.06387      0.02642  ...   \n",
       "2          0.10770           0.07804         0.03046      0.02480  ...   \n",
       "3          0.11640           0.11360         0.04635      0.04796  ...   \n",
       "4          0.07963           0.06934         0.03393      0.02657  ...   \n",
       "\n",
       "   radius_worst  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0         13.50          15.64            86.97       549.1            0.1385   \n",
       "1         11.88          22.94            78.28       424.8            0.1213   \n",
       "2         12.41          26.44            79.93       471.4            0.1369   \n",
       "3         11.92          15.77            76.53       434.0            0.1367   \n",
       "4         16.20          15.73           104.50       819.1            0.1126   \n",
       "\n",
       "   compactness_worst  concavity_worst  points_worst  symmetry_worst  \\\n",
       "0             0.1266          0.12420       0.09391          0.2827   \n",
       "1             0.2515          0.19160       0.07926          0.2940   \n",
       "2             0.1482          0.10670       0.07431          0.2998   \n",
       "3             0.1822          0.08669       0.08611          0.2102   \n",
       "4             0.1737          0.13620       0.08178          0.2487   \n",
       "\n",
       "   dimension_worst  \n",
       "0          0.06771  \n",
       "1          0.07587  \n",
       "2          0.07881  \n",
       "3          0.06784  \n",
       "4          0.06766  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the data\n",
    "data = pd.read_csv(\"https://raw.githubusercontent.com/Mounika-Kajjam/Datasets/master/wbcd.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "B    357\n",
       "M    212\n",
       "Name: diagnosis, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for frequency of B and M\n",
    "data.diagnosis.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                   0\n",
       "diagnosis            0\n",
       "radius_mean          0\n",
       "texture_mean         0\n",
       "perimeter_mean       0\n",
       "area_mean            0\n",
       "smoothness_mean      0\n",
       "compactness_mean     0\n",
       "concavity_mean       0\n",
       "points_mean          0\n",
       "symmetry_mean        0\n",
       "dimension_mean       0\n",
       "radius_se            0\n",
       "texture_se           0\n",
       "perimeter_se         0\n",
       "area_se              0\n",
       "smoothness_se        0\n",
       "compactness_se       0\n",
       "concavity_se         0\n",
       "points_se            0\n",
       "symmetry_se          0\n",
       "dimension_se         0\n",
       "radius_worst         0\n",
       "texture_worst        0\n",
       "perimeter_worst      0\n",
       "area_worst           0\n",
       "smoothness_worst     0\n",
       "compactness_worst    0\n",
       "concavity_worst      0\n",
       "points_worst         0\n",
       "symmetry_worst       0\n",
       "dimension_worst      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into input and output--> Train and test\n",
    "# Train--> Building the model\n",
    "# Test--> How well the model has learnt(Generaize on unseen data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>12.32</td>\n",
       "      <td>12.39</td>\n",
       "      <td>78.85</td>\n",
       "      <td>464.1</td>\n",
       "      <td>0.10280</td>\n",
       "      <td>0.06981</td>\n",
       "      <td>0.03987</td>\n",
       "      <td>0.03700</td>\n",
       "      <td>0.1959</td>\n",
       "      <td>0.05955</td>\n",
       "      <td>...</td>\n",
       "      <td>13.50</td>\n",
       "      <td>15.64</td>\n",
       "      <td>86.97</td>\n",
       "      <td>549.1</td>\n",
       "      <td>0.1385</td>\n",
       "      <td>0.1266</td>\n",
       "      <td>0.12420</td>\n",
       "      <td>0.09391</td>\n",
       "      <td>0.2827</td>\n",
       "      <td>0.06771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>10.60</td>\n",
       "      <td>18.95</td>\n",
       "      <td>69.28</td>\n",
       "      <td>346.4</td>\n",
       "      <td>0.09688</td>\n",
       "      <td>0.11470</td>\n",
       "      <td>0.06387</td>\n",
       "      <td>0.02642</td>\n",
       "      <td>0.1922</td>\n",
       "      <td>0.06491</td>\n",
       "      <td>...</td>\n",
       "      <td>11.88</td>\n",
       "      <td>22.94</td>\n",
       "      <td>78.28</td>\n",
       "      <td>424.8</td>\n",
       "      <td>0.1213</td>\n",
       "      <td>0.2515</td>\n",
       "      <td>0.19160</td>\n",
       "      <td>0.07926</td>\n",
       "      <td>0.2940</td>\n",
       "      <td>0.07587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>11.04</td>\n",
       "      <td>16.83</td>\n",
       "      <td>70.92</td>\n",
       "      <td>373.2</td>\n",
       "      <td>0.10770</td>\n",
       "      <td>0.07804</td>\n",
       "      <td>0.03046</td>\n",
       "      <td>0.02480</td>\n",
       "      <td>0.1714</td>\n",
       "      <td>0.06340</td>\n",
       "      <td>...</td>\n",
       "      <td>12.41</td>\n",
       "      <td>26.44</td>\n",
       "      <td>79.93</td>\n",
       "      <td>471.4</td>\n",
       "      <td>0.1369</td>\n",
       "      <td>0.1482</td>\n",
       "      <td>0.10670</td>\n",
       "      <td>0.07431</td>\n",
       "      <td>0.2998</td>\n",
       "      <td>0.07881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>11.28</td>\n",
       "      <td>13.39</td>\n",
       "      <td>73.00</td>\n",
       "      <td>384.8</td>\n",
       "      <td>0.11640</td>\n",
       "      <td>0.11360</td>\n",
       "      <td>0.04635</td>\n",
       "      <td>0.04796</td>\n",
       "      <td>0.1771</td>\n",
       "      <td>0.06072</td>\n",
       "      <td>...</td>\n",
       "      <td>11.92</td>\n",
       "      <td>15.77</td>\n",
       "      <td>76.53</td>\n",
       "      <td>434.0</td>\n",
       "      <td>0.1367</td>\n",
       "      <td>0.1822</td>\n",
       "      <td>0.08669</td>\n",
       "      <td>0.08611</td>\n",
       "      <td>0.2102</td>\n",
       "      <td>0.06784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>15.19</td>\n",
       "      <td>13.21</td>\n",
       "      <td>97.65</td>\n",
       "      <td>711.8</td>\n",
       "      <td>0.07963</td>\n",
       "      <td>0.06934</td>\n",
       "      <td>0.03393</td>\n",
       "      <td>0.02657</td>\n",
       "      <td>0.1721</td>\n",
       "      <td>0.05544</td>\n",
       "      <td>...</td>\n",
       "      <td>16.20</td>\n",
       "      <td>15.73</td>\n",
       "      <td>104.50</td>\n",
       "      <td>819.1</td>\n",
       "      <td>0.1126</td>\n",
       "      <td>0.1737</td>\n",
       "      <td>0.13620</td>\n",
       "      <td>0.08178</td>\n",
       "      <td>0.2487</td>\n",
       "      <td>0.06766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "0        12.32         12.39           78.85      464.1          0.10280   \n",
       "1        10.60         18.95           69.28      346.4          0.09688   \n",
       "2        11.04         16.83           70.92      373.2          0.10770   \n",
       "3        11.28         13.39           73.00      384.8          0.11640   \n",
       "4        15.19         13.21           97.65      711.8          0.07963   \n",
       "\n",
       "   compactness_mean  concavity_mean  points_mean  symmetry_mean  \\\n",
       "0           0.06981         0.03987      0.03700         0.1959   \n",
       "1           0.11470         0.06387      0.02642         0.1922   \n",
       "2           0.07804         0.03046      0.02480         0.1714   \n",
       "3           0.11360         0.04635      0.04796         0.1771   \n",
       "4           0.06934         0.03393      0.02657         0.1721   \n",
       "\n",
       "   dimension_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0         0.05955  ...         13.50          15.64            86.97   \n",
       "1         0.06491  ...         11.88          22.94            78.28   \n",
       "2         0.06340  ...         12.41          26.44            79.93   \n",
       "3         0.06072  ...         11.92          15.77            76.53   \n",
       "4         0.05544  ...         16.20          15.73           104.50   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0       549.1            0.1385             0.1266          0.12420   \n",
       "1       424.8            0.1213             0.2515          0.19160   \n",
       "2       471.4            0.1369             0.1482          0.10670   \n",
       "3       434.0            0.1367             0.1822          0.08669   \n",
       "4       819.1            0.1126             0.1737          0.13620   \n",
       "\n",
       "   points_worst  symmetry_worst  dimension_worst  \n",
       "0       0.09391          0.2827          0.06771  \n",
       "1       0.07926          0.2940          0.07587  \n",
       "2       0.07431          0.2998          0.07881  \n",
       "3       0.08611          0.2102          0.06784  \n",
       "4       0.08178          0.2487          0.06766  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preparing Input and Output\n",
    "# Drop the id and diagnosis columns\n",
    "X = data.drop(['id', 'diagnosis'], axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    B\n",
       "1    B\n",
       "2    B\n",
       "3    B\n",
       "4    B\n",
       "Name: diagnosis, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accessing Output Column\n",
    "y = data.diagnosis\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing Training and Testing Data\n",
    "# Storing 70% of the data(569 rows) into training and remaining 30% of the data into testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, \n",
    "                                                    random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(398, 30)\n",
      "(171, 30)\n",
      "(398,)\n",
      "(171,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>431</td>\n",
       "      <td>18.310</td>\n",
       "      <td>20.58</td>\n",
       "      <td>120.80</td>\n",
       "      <td>1052.0</td>\n",
       "      <td>0.10680</td>\n",
       "      <td>0.12480</td>\n",
       "      <td>0.15690</td>\n",
       "      <td>0.09451</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.05941</td>\n",
       "      <td>...</td>\n",
       "      <td>21.860</td>\n",
       "      <td>26.20</td>\n",
       "      <td>142.20</td>\n",
       "      <td>1493.0</td>\n",
       "      <td>0.1492</td>\n",
       "      <td>0.2536</td>\n",
       "      <td>0.3759</td>\n",
       "      <td>0.15100</td>\n",
       "      <td>0.3074</td>\n",
       "      <td>0.07863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>389</td>\n",
       "      <td>16.300</td>\n",
       "      <td>15.70</td>\n",
       "      <td>104.70</td>\n",
       "      <td>819.8</td>\n",
       "      <td>0.09427</td>\n",
       "      <td>0.06712</td>\n",
       "      <td>0.05526</td>\n",
       "      <td>0.04563</td>\n",
       "      <td>0.1711</td>\n",
       "      <td>0.05657</td>\n",
       "      <td>...</td>\n",
       "      <td>17.320</td>\n",
       "      <td>17.76</td>\n",
       "      <td>109.80</td>\n",
       "      <td>928.2</td>\n",
       "      <td>0.1354</td>\n",
       "      <td>0.1361</td>\n",
       "      <td>0.1947</td>\n",
       "      <td>0.13570</td>\n",
       "      <td>0.2300</td>\n",
       "      <td>0.07230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>309</td>\n",
       "      <td>13.560</td>\n",
       "      <td>13.90</td>\n",
       "      <td>88.59</td>\n",
       "      <td>561.3</td>\n",
       "      <td>0.10510</td>\n",
       "      <td>0.11920</td>\n",
       "      <td>0.07860</td>\n",
       "      <td>0.04451</td>\n",
       "      <td>0.1962</td>\n",
       "      <td>0.06303</td>\n",
       "      <td>...</td>\n",
       "      <td>14.980</td>\n",
       "      <td>17.13</td>\n",
       "      <td>101.10</td>\n",
       "      <td>686.6</td>\n",
       "      <td>0.1376</td>\n",
       "      <td>0.2698</td>\n",
       "      <td>0.2577</td>\n",
       "      <td>0.09090</td>\n",
       "      <td>0.3065</td>\n",
       "      <td>0.08177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>111</td>\n",
       "      <td>8.219</td>\n",
       "      <td>20.70</td>\n",
       "      <td>53.27</td>\n",
       "      <td>203.9</td>\n",
       "      <td>0.09405</td>\n",
       "      <td>0.13050</td>\n",
       "      <td>0.13210</td>\n",
       "      <td>0.02168</td>\n",
       "      <td>0.2222</td>\n",
       "      <td>0.08261</td>\n",
       "      <td>...</td>\n",
       "      <td>9.092</td>\n",
       "      <td>29.72</td>\n",
       "      <td>58.08</td>\n",
       "      <td>249.8</td>\n",
       "      <td>0.1630</td>\n",
       "      <td>0.4310</td>\n",
       "      <td>0.5381</td>\n",
       "      <td>0.07879</td>\n",
       "      <td>0.3322</td>\n",
       "      <td>0.14860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>13.660</td>\n",
       "      <td>15.15</td>\n",
       "      <td>88.27</td>\n",
       "      <td>580.6</td>\n",
       "      <td>0.08268</td>\n",
       "      <td>0.07548</td>\n",
       "      <td>0.04249</td>\n",
       "      <td>0.02471</td>\n",
       "      <td>0.1792</td>\n",
       "      <td>0.05897</td>\n",
       "      <td>...</td>\n",
       "      <td>14.540</td>\n",
       "      <td>19.64</td>\n",
       "      <td>97.96</td>\n",
       "      <td>657.0</td>\n",
       "      <td>0.1275</td>\n",
       "      <td>0.3104</td>\n",
       "      <td>0.2569</td>\n",
       "      <td>0.10540</td>\n",
       "      <td>0.3387</td>\n",
       "      <td>0.09638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>369</td>\n",
       "      <td>19.450</td>\n",
       "      <td>19.33</td>\n",
       "      <td>126.50</td>\n",
       "      <td>1169.0</td>\n",
       "      <td>0.10350</td>\n",
       "      <td>0.11880</td>\n",
       "      <td>0.13790</td>\n",
       "      <td>0.08591</td>\n",
       "      <td>0.1776</td>\n",
       "      <td>0.05647</td>\n",
       "      <td>...</td>\n",
       "      <td>25.700</td>\n",
       "      <td>24.57</td>\n",
       "      <td>163.10</td>\n",
       "      <td>1972.0</td>\n",
       "      <td>0.1497</td>\n",
       "      <td>0.3161</td>\n",
       "      <td>0.4317</td>\n",
       "      <td>0.19990</td>\n",
       "      <td>0.3379</td>\n",
       "      <td>0.08950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>12.450</td>\n",
       "      <td>16.41</td>\n",
       "      <td>82.85</td>\n",
       "      <td>476.7</td>\n",
       "      <td>0.09514</td>\n",
       "      <td>0.15110</td>\n",
       "      <td>0.15440</td>\n",
       "      <td>0.04846</td>\n",
       "      <td>0.2082</td>\n",
       "      <td>0.07325</td>\n",
       "      <td>...</td>\n",
       "      <td>13.780</td>\n",
       "      <td>21.03</td>\n",
       "      <td>97.82</td>\n",
       "      <td>580.6</td>\n",
       "      <td>0.1175</td>\n",
       "      <td>0.4061</td>\n",
       "      <td>0.4896</td>\n",
       "      <td>0.13420</td>\n",
       "      <td>0.3231</td>\n",
       "      <td>0.10340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>527</td>\n",
       "      <td>17.950</td>\n",
       "      <td>20.01</td>\n",
       "      <td>114.20</td>\n",
       "      <td>982.0</td>\n",
       "      <td>0.08402</td>\n",
       "      <td>0.06722</td>\n",
       "      <td>0.07293</td>\n",
       "      <td>0.05596</td>\n",
       "      <td>0.2129</td>\n",
       "      <td>0.05025</td>\n",
       "      <td>...</td>\n",
       "      <td>20.580</td>\n",
       "      <td>27.83</td>\n",
       "      <td>129.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.1072</td>\n",
       "      <td>0.1202</td>\n",
       "      <td>0.2249</td>\n",
       "      <td>0.11850</td>\n",
       "      <td>0.4882</td>\n",
       "      <td>0.06111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>11.460</td>\n",
       "      <td>18.16</td>\n",
       "      <td>73.59</td>\n",
       "      <td>403.1</td>\n",
       "      <td>0.08853</td>\n",
       "      <td>0.07694</td>\n",
       "      <td>0.03344</td>\n",
       "      <td>0.01502</td>\n",
       "      <td>0.1411</td>\n",
       "      <td>0.06243</td>\n",
       "      <td>...</td>\n",
       "      <td>12.680</td>\n",
       "      <td>21.61</td>\n",
       "      <td>82.69</td>\n",
       "      <td>489.8</td>\n",
       "      <td>0.1144</td>\n",
       "      <td>0.1789</td>\n",
       "      <td>0.1226</td>\n",
       "      <td>0.05509</td>\n",
       "      <td>0.2208</td>\n",
       "      <td>0.07638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>265</td>\n",
       "      <td>13.000</td>\n",
       "      <td>21.82</td>\n",
       "      <td>87.50</td>\n",
       "      <td>519.8</td>\n",
       "      <td>0.12730</td>\n",
       "      <td>0.19320</td>\n",
       "      <td>0.18590</td>\n",
       "      <td>0.09353</td>\n",
       "      <td>0.2350</td>\n",
       "      <td>0.07389</td>\n",
       "      <td>...</td>\n",
       "      <td>15.490</td>\n",
       "      <td>30.73</td>\n",
       "      <td>106.20</td>\n",
       "      <td>739.3</td>\n",
       "      <td>0.1703</td>\n",
       "      <td>0.5401</td>\n",
       "      <td>0.5390</td>\n",
       "      <td>0.20600</td>\n",
       "      <td>0.4378</td>\n",
       "      <td>0.10720</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>398 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "431       18.310         20.58          120.80     1052.0          0.10680   \n",
       "389       16.300         15.70          104.70      819.8          0.09427   \n",
       "309       13.560         13.90           88.59      561.3          0.10510   \n",
       "111        8.219         20.70           53.27      203.9          0.09405   \n",
       "35        13.660         15.15           88.27      580.6          0.08268   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "369       19.450         19.33          126.50     1169.0          0.10350   \n",
       "320       12.450         16.41           82.85      476.7          0.09514   \n",
       "527       17.950         20.01          114.20      982.0          0.08402   \n",
       "125       11.460         18.16           73.59      403.1          0.08853   \n",
       "265       13.000         21.82           87.50      519.8          0.12730   \n",
       "\n",
       "     compactness_mean  concavity_mean  points_mean  symmetry_mean  \\\n",
       "431           0.12480         0.15690      0.09451         0.1860   \n",
       "389           0.06712         0.05526      0.04563         0.1711   \n",
       "309           0.11920         0.07860      0.04451         0.1962   \n",
       "111           0.13050         0.13210      0.02168         0.2222   \n",
       "35            0.07548         0.04249      0.02471         0.1792   \n",
       "..                ...             ...          ...            ...   \n",
       "369           0.11880         0.13790      0.08591         0.1776   \n",
       "320           0.15110         0.15440      0.04846         0.2082   \n",
       "527           0.06722         0.07293      0.05596         0.2129   \n",
       "125           0.07694         0.03344      0.01502         0.1411   \n",
       "265           0.19320         0.18590      0.09353         0.2350   \n",
       "\n",
       "     dimension_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "431         0.05941  ...        21.860          26.20           142.20   \n",
       "389         0.05657  ...        17.320          17.76           109.80   \n",
       "309         0.06303  ...        14.980          17.13           101.10   \n",
       "111         0.08261  ...         9.092          29.72            58.08   \n",
       "35          0.05897  ...        14.540          19.64            97.96   \n",
       "..              ...  ...           ...            ...              ...   \n",
       "369         0.05647  ...        25.700          24.57           163.10   \n",
       "320         0.07325  ...        13.780          21.03            97.82   \n",
       "527         0.05025  ...        20.580          27.83           129.20   \n",
       "125         0.06243  ...        12.680          21.61            82.69   \n",
       "265         0.07389  ...        15.490          30.73           106.20   \n",
       "\n",
       "     area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "431      1493.0            0.1492             0.2536           0.3759   \n",
       "389       928.2            0.1354             0.1361           0.1947   \n",
       "309       686.6            0.1376             0.2698           0.2577   \n",
       "111       249.8            0.1630             0.4310           0.5381   \n",
       "35        657.0            0.1275             0.3104           0.2569   \n",
       "..          ...               ...                ...              ...   \n",
       "369      1972.0            0.1497             0.3161           0.4317   \n",
       "320       580.6            0.1175             0.4061           0.4896   \n",
       "527      1261.0            0.1072             0.1202           0.2249   \n",
       "125       489.8            0.1144             0.1789           0.1226   \n",
       "265       739.3            0.1703             0.5401           0.5390   \n",
       "\n",
       "     points_worst  symmetry_worst  dimension_worst  \n",
       "431       0.15100          0.3074          0.07863  \n",
       "389       0.13570          0.2300          0.07230  \n",
       "309       0.09090          0.3065          0.08177  \n",
       "111       0.07879          0.3322          0.14860  \n",
       "35        0.10540          0.3387          0.09638  \n",
       "..            ...             ...              ...  \n",
       "369       0.19990          0.3379          0.08950  \n",
       "320       0.13420          0.3231          0.10340  \n",
       "527       0.11850          0.4882          0.06111  \n",
       "125       0.05509          0.2208          0.07638  \n",
       "265       0.20600          0.4378          0.10720  \n",
       "\n",
       "[398 rows x 30 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Before Splitting if you apply standardization--> you are considering whole\n",
    "# you are including test data also into training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-0.077524</td>\n",
       "      <td>0.385200</td>\n",
       "      <td>-0.028576</td>\n",
       "      <td>-0.181721</td>\n",
       "      <td>1.617086</td>\n",
       "      <td>1.210962</td>\n",
       "      <td>0.105416</td>\n",
       "      <td>0.353917</td>\n",
       "      <td>1.441699</td>\n",
       "      <td>1.621128</td>\n",
       "      <td>...</td>\n",
       "      <td>0.217083</td>\n",
       "      <td>0.452310</td>\n",
       "      <td>0.154687</td>\n",
       "      <td>0.075338</td>\n",
       "      <td>1.470507</td>\n",
       "      <td>0.755583</td>\n",
       "      <td>0.005892</td>\n",
       "      <td>0.674696</td>\n",
       "      <td>0.532371</td>\n",
       "      <td>1.661987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.644210</td>\n",
       "      <td>-0.376307</td>\n",
       "      <td>-0.630196</td>\n",
       "      <td>-0.629478</td>\n",
       "      <td>0.808428</td>\n",
       "      <td>-0.078482</td>\n",
       "      <td>-0.406623</td>\n",
       "      <td>-0.055776</td>\n",
       "      <td>-0.746101</td>\n",
       "      <td>0.554649</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.541540</td>\n",
       "      <td>0.425511</td>\n",
       "      <td>-0.526524</td>\n",
       "      <td>-0.549443</td>\n",
       "      <td>0.146485</td>\n",
       "      <td>-0.400616</td>\n",
       "      <td>-0.607829</td>\n",
       "      <td>-0.159783</td>\n",
       "      <td>-0.649397</td>\n",
       "      <td>-0.331922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-0.392671</td>\n",
       "      <td>-0.471786</td>\n",
       "      <td>-0.431337</td>\n",
       "      <td>-0.427265</td>\n",
       "      <td>-0.688285</td>\n",
       "      <td>-0.898236</td>\n",
       "      <td>-0.696996</td>\n",
       "      <td>-0.630673</td>\n",
       "      <td>-0.010737</td>\n",
       "      <td>-0.617927</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.362539</td>\n",
       "      <td>-0.550999</td>\n",
       "      <td>-0.430883</td>\n",
       "      <td>-0.402265</td>\n",
       "      <td>-0.391807</td>\n",
       "      <td>-0.613767</td>\n",
       "      <td>-0.364118</td>\n",
       "      <td>-0.197839</td>\n",
       "      <td>0.654169</td>\n",
       "      <td>-0.558780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-0.415801</td>\n",
       "      <td>-0.665074</td>\n",
       "      <td>-0.404851</td>\n",
       "      <td>-0.475219</td>\n",
       "      <td>1.400979</td>\n",
       "      <td>0.139137</td>\n",
       "      <td>-0.325629</td>\n",
       "      <td>-0.363643</td>\n",
       "      <td>0.516091</td>\n",
       "      <td>0.465086</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.526623</td>\n",
       "      <td>-0.676622</td>\n",
       "      <td>-0.583600</td>\n",
       "      <td>-0.549987</td>\n",
       "      <td>1.149269</td>\n",
       "      <td>-0.465763</td>\n",
       "      <td>-0.363183</td>\n",
       "      <td>-0.417921</td>\n",
       "      <td>0.464889</td>\n",
       "      <td>-0.448273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-0.629754</td>\n",
       "      <td>-0.604526</td>\n",
       "      <td>-0.499866</td>\n",
       "      <td>-0.603191</td>\n",
       "      <td>0.933909</td>\n",
       "      <td>1.316231</td>\n",
       "      <td>1.011138</td>\n",
       "      <td>0.733116</td>\n",
       "      <td>3.205109</td>\n",
       "      <td>1.510897</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.490396</td>\n",
       "      <td>0.157515</td>\n",
       "      <td>-0.421319</td>\n",
       "      <td>-0.478029</td>\n",
       "      <td>0.302763</td>\n",
       "      <td>1.014906</td>\n",
       "      <td>0.860048</td>\n",
       "      <td>1.146956</td>\n",
       "      <td>4.775544</td>\n",
       "      <td>1.019133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>166</td>\n",
       "      <td>-0.913098</td>\n",
       "      <td>1.172324</td>\n",
       "      <td>-0.924489</td>\n",
       "      <td>-0.806559</td>\n",
       "      <td>-0.960859</td>\n",
       "      <td>-0.673919</td>\n",
       "      <td>-0.874780</td>\n",
       "      <td>-1.016766</td>\n",
       "      <td>0.636823</td>\n",
       "      <td>0.073768</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.641695</td>\n",
       "      <td>1.006726</td>\n",
       "      <td>-0.669060</td>\n",
       "      <td>-0.634088</td>\n",
       "      <td>-0.482969</td>\n",
       "      <td>-0.540397</td>\n",
       "      <td>-0.957069</td>\n",
       "      <td>-1.204563</td>\n",
       "      <td>0.306881</td>\n",
       "      <td>-0.401520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>167</td>\n",
       "      <td>-1.534429</td>\n",
       "      <td>-1.100553</td>\n",
       "      <td>-1.532835</td>\n",
       "      <td>-1.194808</td>\n",
       "      <td>-0.301385</td>\n",
       "      <td>-1.119109</td>\n",
       "      <td>-1.068863</td>\n",
       "      <td>-1.233148</td>\n",
       "      <td>-0.292443</td>\n",
       "      <td>0.619409</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.444641</td>\n",
       "      <td>-1.406910</td>\n",
       "      <td>-1.457018</td>\n",
       "      <td>-1.080697</td>\n",
       "      <td>-0.665293</td>\n",
       "      <td>-1.126909</td>\n",
       "      <td>-1.246809</td>\n",
       "      <td>-1.703417</td>\n",
       "      <td>-0.461762</td>\n",
       "      <td>-0.283575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>168</td>\n",
       "      <td>-0.112219</td>\n",
       "      <td>0.620406</td>\n",
       "      <td>-0.156383</td>\n",
       "      <td>-0.230541</td>\n",
       "      <td>-1.125379</td>\n",
       "      <td>-0.356773</td>\n",
       "      <td>-0.558329</td>\n",
       "      <td>-0.665145</td>\n",
       "      <td>-0.610735</td>\n",
       "      <td>-0.572457</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.264515</td>\n",
       "      <td>0.770555</td>\n",
       "      <td>-0.244537</td>\n",
       "      <td>-0.351514</td>\n",
       "      <td>-1.346840</td>\n",
       "      <td>-0.479045</td>\n",
       "      <td>-0.567132</td>\n",
       "      <td>-0.757521</td>\n",
       "      <td>-0.702066</td>\n",
       "      <td>-0.721353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>169</td>\n",
       "      <td>-0.005242</td>\n",
       "      <td>-0.495074</td>\n",
       "      <td>0.023136</td>\n",
       "      <td>-0.110946</td>\n",
       "      <td>0.968765</td>\n",
       "      <td>0.510448</td>\n",
       "      <td>0.158451</td>\n",
       "      <td>0.157954</td>\n",
       "      <td>0.388043</td>\n",
       "      <td>-0.199052</td>\n",
       "      <td>...</td>\n",
       "      <td>0.074308</td>\n",
       "      <td>-0.564399</td>\n",
       "      <td>0.077557</td>\n",
       "      <td>-0.053352</td>\n",
       "      <td>0.854077</td>\n",
       "      <td>0.489936</td>\n",
       "      <td>0.254280</td>\n",
       "      <td>0.396537</td>\n",
       "      <td>0.321694</td>\n",
       "      <td>-0.225665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1.397019</td>\n",
       "      <td>0.187255</td>\n",
       "      <td>1.262111</td>\n",
       "      <td>1.332277</td>\n",
       "      <td>-0.451265</td>\n",
       "      <td>-0.811342</td>\n",
       "      <td>-0.063341</td>\n",
       "      <td>0.316263</td>\n",
       "      <td>-0.921710</td>\n",
       "      <td>-1.761567</td>\n",
       "      <td>...</td>\n",
       "      <td>0.835062</td>\n",
       "      <td>-0.190880</td>\n",
       "      <td>0.722362</td>\n",
       "      <td>0.689788</td>\n",
       "      <td>-0.313668</td>\n",
       "      <td>-0.839567</td>\n",
       "      <td>-0.213027</td>\n",
       "      <td>0.274269</td>\n",
       "      <td>-0.502910</td>\n",
       "      <td>-1.405115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>171 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "0      -0.077524      0.385200       -0.028576  -0.181721         1.617086   \n",
       "1      -0.644210     -0.376307       -0.630196  -0.629478         0.808428   \n",
       "2      -0.392671     -0.471786       -0.431337  -0.427265        -0.688285   \n",
       "3      -0.415801     -0.665074       -0.404851  -0.475219         1.400979   \n",
       "4      -0.629754     -0.604526       -0.499866  -0.603191         0.933909   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "166    -0.913098      1.172324       -0.924489  -0.806559        -0.960859   \n",
       "167    -1.534429     -1.100553       -1.532835  -1.194808        -0.301385   \n",
       "168    -0.112219      0.620406       -0.156383  -0.230541        -1.125379   \n",
       "169    -0.005242     -0.495074        0.023136  -0.110946         0.968765   \n",
       "170     1.397019      0.187255        1.262111   1.332277        -0.451265   \n",
       "\n",
       "     compactness_mean  concavity_mean  points_mean  symmetry_mean  \\\n",
       "0            1.210962        0.105416     0.353917       1.441699   \n",
       "1           -0.078482       -0.406623    -0.055776      -0.746101   \n",
       "2           -0.898236       -0.696996    -0.630673      -0.010737   \n",
       "3            0.139137       -0.325629    -0.363643       0.516091   \n",
       "4            1.316231        1.011138     0.733116       3.205109   \n",
       "..                ...             ...          ...            ...   \n",
       "166         -0.673919       -0.874780    -1.016766       0.636823   \n",
       "167         -1.119109       -1.068863    -1.233148      -0.292443   \n",
       "168         -0.356773       -0.558329    -0.665145      -0.610735   \n",
       "169          0.510448        0.158451     0.157954       0.388043   \n",
       "170         -0.811342       -0.063341     0.316263      -0.921710   \n",
       "\n",
       "     dimension_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0          1.621128  ...      0.217083       0.452310         0.154687   \n",
       "1          0.554649  ...     -0.541540       0.425511        -0.526524   \n",
       "2         -0.617927  ...     -0.362539      -0.550999        -0.430883   \n",
       "3          0.465086  ...     -0.526623      -0.676622        -0.583600   \n",
       "4          1.510897  ...     -0.490396       0.157515        -0.421319   \n",
       "..              ...  ...           ...            ...              ...   \n",
       "166        0.073768  ...     -0.641695       1.006726        -0.669060   \n",
       "167        0.619409  ...     -1.444641      -1.406910        -1.457018   \n",
       "168       -0.572457  ...     -0.264515       0.770555        -0.244537   \n",
       "169       -0.199052  ...      0.074308      -0.564399         0.077557   \n",
       "170       -1.761567  ...      0.835062      -0.190880         0.722362   \n",
       "\n",
       "     area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0      0.075338          1.470507           0.755583         0.005892   \n",
       "1     -0.549443          0.146485          -0.400616        -0.607829   \n",
       "2     -0.402265         -0.391807          -0.613767        -0.364118   \n",
       "3     -0.549987          1.149269          -0.465763        -0.363183   \n",
       "4     -0.478029          0.302763           1.014906         0.860048   \n",
       "..          ...               ...                ...              ...   \n",
       "166   -0.634088         -0.482969          -0.540397        -0.957069   \n",
       "167   -1.080697         -0.665293          -1.126909        -1.246809   \n",
       "168   -0.351514         -1.346840          -0.479045        -0.567132   \n",
       "169   -0.053352          0.854077           0.489936         0.254280   \n",
       "170    0.689788         -0.313668          -0.839567        -0.213027   \n",
       "\n",
       "     points_worst  symmetry_worst  dimension_worst  \n",
       "0        0.674696        0.532371         1.661987  \n",
       "1       -0.159783       -0.649397        -0.331922  \n",
       "2       -0.197839        0.654169        -0.558780  \n",
       "3       -0.417921        0.464889        -0.448273  \n",
       "4        1.146956        4.775544         1.019133  \n",
       "..            ...             ...              ...  \n",
       "166     -1.204563        0.306881        -0.401520  \n",
       "167     -1.703417       -0.461762        -0.283575  \n",
       "168     -0.757521       -0.702066        -0.721353  \n",
       "169      0.396537        0.321694        -0.225665  \n",
       "170      0.274269       -0.502910        -1.405115  \n",
       "\n",
       "[171 rows x 30 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scaling Data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Scaling for training data\n",
    "scaled_X_train = pd.DataFrame(scaler.fit_transform(X_train), columns = X_train.columns)\n",
    "scaled_X_train\n",
    "\n",
    "#Scaling for test data\n",
    "#Testing the data based on training data\n",
    "scaled_X_test = pd.DataFrame(scaler.transform(X_test), columns = X_test.columns)\n",
    "scaled_X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='euclidean',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=40, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model Building:\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=40, metric='euclidean')\n",
    "\n",
    "# Apply the knn object on the dataset(Training Phase)\n",
    "# Syntax: objectName.fit(Input, Output)\n",
    "knn.fit(scaled_X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['M', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B', 'B', 'B',\n",
       "       'B', 'M', 'M', 'B', 'B', 'M', 'M', 'B', 'M', 'B', 'B', 'B', 'B',\n",
       "       'B', 'B', 'B', 'M', 'M', 'M', 'M', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'M', 'B', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'M', 'B', 'B', 'B', 'B', 'M', 'B', 'B', 'M', 'B', 'M', 'B', 'B',\n",
       "       'M', 'B', 'B', 'M', 'M', 'B', 'B', 'B', 'M', 'M', 'M', 'B', 'M',\n",
       "       'B', 'B', 'B', 'B', 'B', 'M', 'B', 'M', 'B', 'B', 'M', 'M', 'B',\n",
       "       'B', 'M', 'B', 'M', 'M', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'B', 'B', 'B', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'B', 'M', 'B', 'B', 'B', 'M', 'B', 'M', 'B', 'M', 'M', 'B', 'M',\n",
       "       'B', 'M', 'B', 'M', 'B', 'B', 'B', 'B', 'M', 'B', 'B', 'B', 'M',\n",
       "       'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B', 'B', 'B',\n",
       "       'M', 'B', 'M', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'M', 'M', 'B', 'M', 'M', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'M',\n",
       "       'B', 'B', 'B', 'M', 'B', 'B', 'M', 'B', 'M', 'M', 'B', 'M', 'B',\n",
       "       'B', 'B', 'B', 'B', 'B', 'M', 'B', 'M', 'M', 'M', 'B', 'B', 'M',\n",
       "       'B', 'B', 'B', 'B', 'M', 'B', 'B', 'B', 'M', 'B', 'B', 'M', 'M',\n",
       "       'B', 'M', 'B', 'B', 'B', 'M', 'B', 'M', 'M', 'B', 'B', 'B', 'B',\n",
       "       'B', 'B', 'B', 'B', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'M', 'B', 'B', 'M', 'B', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'B', 'B', 'B', 'B', 'M', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'M',\n",
       "       'B', 'B', 'B', 'B', 'M', 'B', 'M', 'M', 'B', 'B', 'M', 'M', 'B',\n",
       "       'B', 'B', 'B', 'B', 'M', 'B', 'B', 'M', 'B', 'B', 'M', 'B', 'M',\n",
       "       'M', 'M', 'B', 'B', 'B', 'B', 'B', 'M', 'M', 'M', 'B', 'M', 'B',\n",
       "       'M', 'M', 'B', 'B', 'B', 'B', 'M', 'B', 'M', 'M', 'B', 'M', 'B',\n",
       "       'B', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B', 'M', 'M',\n",
       "       'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B', 'B',\n",
       "       'B', 'B', 'M', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'M', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'M',\n",
       "       'M', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'M', 'M', 'B', 'B', 'B',\n",
       "       'B', 'B', 'M', 'M', 'B', 'B', 'B', 'M'], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predictions on the data\n",
    "#predict function--> gives the predicted values\n",
    "# Syntax:objectname.predict(Input)\n",
    "y_train_pred = knn.predict(scaled_X_train)\n",
    "y_train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           B       0.93      1.00      0.96       259\n",
      "           M       1.00      0.85      0.92       139\n",
      "\n",
      "    accuracy                           0.95       398\n",
      "   macro avg       0.96      0.92      0.94       398\n",
      "weighted avg       0.95      0.95      0.95       398\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check the accuracy, classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9532163742690059,\n",
       " 0.9590643274853801,\n",
       " 0.9649122807017544,\n",
       " 0.9649122807017544,\n",
       " 0.9649122807017544,\n",
       " 0.9590643274853801,\n",
       " 0.9707602339181286,\n",
       " 0.9766081871345029,\n",
       " 0.9766081871345029,\n",
       " 0.9766081871345029,\n",
       " 0.9766081871345029,\n",
       " 0.9707602339181286,\n",
       " 0.9707602339181286,\n",
       " 0.9707602339181286,\n",
       " 0.9707602339181286,\n",
       " 0.9649122807017544,\n",
       " 0.9649122807017544,\n",
       " 0.9649122807017544,\n",
       " 0.9649122807017544]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "# Checking for optimum k-value\n",
    "# Build the models with multiple k values\n",
    "scores=[]\n",
    "for k in range(1, 20):\n",
    "    knn_model = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn_model.fit(scaled_X_train, y_train)\n",
    "    pred_test = knn_model.predict(scaled_X_test)\n",
    "    scores.append(accuracy_score(y_test, pred_test))\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x19169615748>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot of K values and Scores\n",
    "plt.plot(range(1,20), scores, marker='o', markerfacecolor='r', linestyle='--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='euclidean',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=7, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optimum k value is 7\n",
    "final_model = KNeighborsClassifier(n_neighbors=7, metric='euclidean')\n",
    "final_model.fit(scaled_X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['M', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B', 'B', 'B',\n",
       "       'B', 'M', 'M', 'B', 'B', 'M', 'M', 'B', 'M', 'B', 'B', 'B', 'B',\n",
       "       'B', 'B', 'B', 'M', 'M', 'M', 'M', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'M', 'B', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B', 'B',\n",
       "       'M', 'B', 'B', 'B', 'B', 'M', 'B', 'B', 'M', 'B', 'M', 'B', 'B',\n",
       "       'M', 'B', 'B', 'M', 'M', 'B', 'B', 'B', 'M', 'M', 'M', 'B', 'M',\n",
       "       'B', 'B', 'B', 'B', 'B', 'M', 'B', 'M', 'B', 'B', 'M', 'M', 'B',\n",
       "       'B', 'M', 'B', 'M', 'M', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'B', 'B', 'B', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'B', 'M', 'B', 'B', 'B', 'M', 'B', 'M', 'B', 'M', 'M', 'B', 'M',\n",
       "       'B', 'M', 'B', 'M', 'B', 'B', 'B', 'B', 'M', 'B', 'B', 'B', 'M',\n",
       "       'M', 'B', 'B', 'B', 'B', 'M', 'B', 'B', 'B', 'M', 'B', 'B', 'B',\n",
       "       'M', 'B', 'M', 'B', 'M', 'B', 'B', 'B', 'B', 'M', 'B', 'B', 'B',\n",
       "       'M', 'M', 'B', 'M', 'M', 'M', 'B', 'B', 'M', 'B', 'B', 'B', 'M',\n",
       "       'M', 'B', 'B', 'M', 'B', 'B', 'M', 'B', 'M', 'M', 'B', 'M', 'B',\n",
       "       'B', 'B', 'B', 'B', 'B', 'M', 'B', 'M', 'M', 'M', 'B', 'B', 'M',\n",
       "       'B', 'B', 'B', 'B', 'M', 'B', 'B', 'B', 'M', 'M', 'B', 'M', 'M',\n",
       "       'B', 'M', 'B', 'B', 'B', 'M', 'B', 'M', 'M', 'B', 'B', 'B', 'B',\n",
       "       'B', 'B', 'B', 'B', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'M', 'B', 'B', 'M', 'B', 'M', 'M', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'B', 'B', 'B', 'B', 'M', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'M',\n",
       "       'B', 'B', 'B', 'B', 'M', 'B', 'M', 'M', 'M', 'B', 'M', 'M', 'B',\n",
       "       'B', 'B', 'M', 'B', 'M', 'B', 'B', 'M', 'B', 'M', 'M', 'B', 'M',\n",
       "       'M', 'M', 'B', 'B', 'B', 'B', 'B', 'M', 'M', 'M', 'B', 'M', 'B',\n",
       "       'M', 'M', 'B', 'B', 'B', 'B', 'M', 'B', 'M', 'M', 'B', 'B', 'B',\n",
       "       'B', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B', 'M', 'M',\n",
       "       'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'M', 'B',\n",
       "       'B', 'B', 'M', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'M', 'B', 'M', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'M',\n",
       "       'M', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'M', 'M', 'B', 'B', 'B',\n",
       "       'B', 'B', 'M', 'M', 'B', 'M', 'B', 'M'], dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction on  training data\n",
    "final_train_pred = final_model.predict(scaled_X_train)\n",
    "final_train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x191696daec8>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confusion Matrix of Training data\n",
    "#Syntax: confusion_matrix(ActualValues, Predicted Values)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "sns.heatmap(confusion_matrix(y_train, final_train_pred), annot=True, \n",
    "            fmt='d', annot_kws={'va':'top','ha':'right'}) # d--> integer formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           B       0.96      0.99      0.98       259\n",
      "           M       0.98      0.92      0.95       139\n",
      "\n",
      "    accuracy                           0.97       398\n",
      "   macro avg       0.97      0.96      0.96       398\n",
      "weighted avg       0.97      0.97      0.97       398\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report for training Data\n",
    "# Precision--> PPV--> Out of the positive predicted values, how many truely positive\n",
    "print(classification_report(y_train, final_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['M', 'B', 'B', 'B', 'M', 'B', 'B', 'B', 'M', 'B', 'B', 'M', 'M',\n",
       "       'B', 'M', 'M', 'B', 'B', 'B', 'M', 'M', 'M', 'B', 'M', 'M', 'B',\n",
       "       'B', 'M', 'M', 'M', 'B', 'B', 'M', 'M', 'B', 'B', 'B', 'B', 'B',\n",
       "       'B', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'M', 'M', 'B', 'B', 'B',\n",
       "       'B', 'B', 'M', 'M', 'M', 'B', 'M', 'B', 'B', 'M', 'B', 'M', 'M',\n",
       "       'B', 'M', 'B', 'B', 'M', 'M', 'M', 'B', 'M', 'B', 'B', 'B', 'M',\n",
       "       'M', 'B', 'M', 'M', 'B', 'B', 'B', 'M', 'M', 'B', 'B', 'B', 'B',\n",
       "       'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B', 'B', 'B',\n",
       "       'B', 'M', 'B', 'B', 'M', 'M', 'M', 'B', 'B', 'M', 'B', 'M', 'B',\n",
       "       'B', 'M', 'M', 'M', 'M', 'B', 'M', 'M', 'M', 'B', 'B', 'M', 'M',\n",
       "       'B', 'B', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'M',\n",
       "       'M', 'M', 'B', 'B', 'M', 'B', 'B', 'B', 'B', 'M', 'B', 'B', 'B',\n",
       "       'M', 'M', 'M', 'M', 'B', 'M', 'M', 'M', 'M', 'B', 'B', 'B', 'B',\n",
       "       'B', 'M'], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predictions on Test Data\n",
    "final_test_pred = final_model.predict(scaled_X_test)  # y_test\n",
    "final_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x191697aef48>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compare actual values of test data(y_test) and final_test_pred(model predicted values)\n",
    "# Confusion_matrix(actualValues, predictedValues)\n",
    "sns.heatmap(confusion_matrix(y_test, final_test_pred), annot=True, fmt='d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           B       0.96      0.99      0.97        98\n",
      "           M       0.99      0.95      0.97        73\n",
      "\n",
      "    accuracy                           0.97       171\n",
      "   macro avg       0.97      0.97      0.97       171\n",
      "weighted avg       0.97      0.97      0.97       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification Report for Test Data\n",
    "print(classification_report(y_test, final_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
